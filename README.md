<<<<<<< HEAD
# ğŸ¤Ÿ Real-Time Sign Language Detection System
> Flask â€¢ MediaPipe â€¢ LSTM â€” Real-time ASL recognition with an elegant UI and image upload
=======
**ğŸ¤Ÿ Real-Time Sign Language Detection System (Flask + MediaPipe + LSTM)**
>>>>>>> a8baf785b3145b7212fc4d6f8c10786412d63986

[![Python](https://img.shields.io/badge/python-3.10+-blue.svg)]()
[![Flask](https://img.shields.io/badge/flask-2.0-lightgrey.svg)]()
[![TensorFlow](https://img.shields.io/badge/tensorflow-keras-orange.svg)]()
[![Status](https://img.shields.io/badge/status-production-brightgreen.svg)]()

---

<<<<<<< HEAD
## âœ¨ Project Overview
=======
**ğŸš€ Features**
ğŸ¥ 1. Real-Time Video Sign Detection
>>>>>>> a8baf785b3145b7212fc4d6f8c10786412d63986

**Real-Time Sign Language Detection System** is an end-to-end project that recognizes a handful of American Sign Language gestures using MediaPipe hand landmarks and an LSTM model. The system supports both **real-time webcam detection** and **single-image upload**, with a polished Flask-based GUI and time-based activation.

Key features:
- Live webcam feed with landmark overlays and smooth predictions.
- Image upload for single-frame analysis.
- Threaded architecture for non-blocking prediction and streaming.
- Time-window control for availability (e.g., 6 PM â€“ 10 PM).
- Clean, modern UI with glassmorphism + soft design.

---

## ğŸ¯ What it Demonstrates

- Real-time computer vision (MediaPipe Hands)
- Sequential deep learning (LSTM with Keras/TensorFlow)
- Production-style engineering (Flask, threading, MJPEG streaming)
- UX/UI for ML applications
- Debugging and robustness (stale buffer handling, smoothing)

---

## ğŸ§­ Quick Links

- **Local Flask app code**: `/mnt/data/app.py`  
  (open this file to review or tweak the backend quickly)

---

## ğŸ“ Repository Structure

project_root/
â”œâ”€ app.py # Flask web app + streaming + prediction
â”œâ”€ dynamic_lstm_model.h5 # Trained LSTM model (not tracked in Git)
â”œâ”€ mp_data/ # (excluded via .gitignore) your dataset images
â”œâ”€ requirements.txt # pip dependencies
â”œâ”€ README.md # (this file)
â””â”€ static/ # optional css/js assets

yaml
Copy code

---

## ğŸš€ Demo / Run Locally

1. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate   # Linux / Mac
   venv\Scripts\activate      # Windows
Install dependencies:

<<<<<<< HEAD
bash
Copy code
=======
Prediction worker thread: Runs ML inference

Video generator: Handles camera + landmark drawing

No blocking, no lag

ğŸ§¼ 5. Smart Input Buffering

Automatically clears buffer when:

No hand detected for long

Hand landmarks vanish

Stale frames detected

Guarantees high accuracy

**ğŸ§  Tech Stack**
Component	Technology
Hand Tracking	MediaPipe Hands
Sequence Model	LSTM (TensorFlow / Keras)
Backend	Flask
Frontend	Custom HTML Template
Real-Time Video	MJPEG Streaming
Threading	Python threading module
ğŸ“¦ Project Structure
ğŸ“ project_root/
â”‚â”€â”€ app.py                 # Flask app with threaded ML pipeline
â”‚â”€â”€ dynamic_lstm_model.h5  # Trained LSTM model
â”‚â”€â”€ mp_data/               # (Excluded from Git using .gitignore)
â”‚â”€â”€ static/                # Optional CSS/JS assets
â”‚â”€â”€ README.md              # Project documentation
â”‚â”€â”€ requirements.txt

**ğŸ“ How It Works**
1ï¸âƒ£ MediaPipe extracts 21 hand landmark coordinates

â†’ Each frame gives (21 Ã— 3) = 63 values.

2ï¸âƒ£ Frames are collected into sequences

â†’ Buffer size = 30 frames.

3ï¸âƒ£ LSTM Model predicts one of the actions:

hello
thanks
i_love_you
please

4ï¸âƒ£ Real-time predictions displayed on top of video
â–¶ï¸ Run the App
Step 1: Install Dependencies
>>>>>>> a8baf785b3145b7212fc4d6f8c10786412d63986
pip install -r requirements.txt
Start the app:

bash
Copy code
python app.py
Open the UI:

<<<<<<< HEAD
cpp
Copy code
http://127.0.0.1:5000
=======
Step 3: Open in browser
http://127.0.0.1:5000
>>>>>>> a8baf785b3145b7212fc4d6f8c10786412d63986
